User-agent: Orthogaffe
Disallow: /

# Crawlers that are kind enough to obey, but which we'd rather not have
# unless they're feeding search engines.
User-agent: UbiCrawler
Disallow: /

User-agent: DOC
Disallow: /

User-agent: Zao
Disallow: /

User-agent: Twiceler
Disallow: /

# Some bots are known to be trouble, particularly those designed to copy
# entire sites or download them for offline viewing. Please obey robots.txt.
#
User-agent: sitecheck.internetseer.com
Disallow: /

User-agent: Zealbot
Disallow: /

User-agent: MSIECrawler
Disallow: /

User-agent: SiteSnagger
Disallow: /

User-agent: WebStripper
Disallow: /

User-agent: WebCopier
Disallow: /

User-agent: Fetch
Disallow: /

User-agent: Offline Explorer
Disallow: /

User-agent: Teleport
Disallow: /

User-agent: TeleportPro
Disallow: /

User-agent: WebZIP
Disallow: /

User-agent: linko
Disallow: /

User-agent: HTTrack
Disallow: /

User-agent: Microsoft.URL.Control
Disallow: /

User-agent: Xenu
Disallow: /

User-agent: larbin
Disallow: /

User-agent: libwww
Disallow: /

User-agent: ZyBORG
Disallow: /

User-agent: Download Ninja
Disallow: /

User-agent: Nutch
Disallow: /

User-agent: spock
Disallow: /

User-agent: OmniExplorer_Bot
Disallow: /

User-agent: TurnitinBot
Disallow: /

User-agent: BecomeBot
Disallow: /

User-agent: genieBot
Disallow: /

User-agent: dotbot
Disallow: /

User-agent: MLBot
Disallow: /

User-agent: 80bot
Disallow: /

User-agent: Linguee Bot
Disallow: /

User-agent: aiHitBot
Disallow: /

User-agent: Exabot
Disallow: /

User-agent: SBIder/Nutch
Disallow: /

User-agent: Jyxobot
Disallow: /

User-agent: mAgent
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: Speedy Spider
Disallow: /

User-agent: ShopWiki
Disallow: /

User-agent: Huasai
Disallow: /

User-agent: DataCha0s
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: Atomic_Email_Hunter
Disallow: /

User-agent: Mp3Bot
Disallow: /

User-agent: WinHttp
Disallow: /

User-agent: betaBot
Disallow: /

User-agent: core-project
Disallow: /

User-agent: panscient.com
Disallow: /

User-agent: Java
Disallow: /

User-agent: libwww-perl
Disallow: /

# Sorry, wget in its recursive mode is a frequent problem.
# Please read the man page and use it properly; there is a
# --wait option you can use to set the delay between hits,
# for instance.
#
User-agent: wget
Disallow: /

#
# A capture bot, downloads gazillions of pages with no public benefit
# http://www.webreaper.net/
User-agent: WebReaper
Disallow: /

# Poorly behaved Crawlers, some of these ignore
# robots.txt but...
#
# The 'grub' distributed client has been *very* poorly behaved.

User-agent: grub-client
Disallow: /

User-agent: k2spider
Disallow: /

# Hits many times per second, not acceptable
# http://www.nameprotect.com/botinfo.html
User-agent: NPBot
Disallow: /

