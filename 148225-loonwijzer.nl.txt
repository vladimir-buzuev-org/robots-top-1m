
# Define access-restrictions for robots/spiders
# http://www.robotstxt.org/wc/norobots.html

# specially for the adsense crawler:
User-agent: Mediapartners-Google
Disallow:

# By default we allow robots to access all areas of our site 
# already accessible to anonymous users
User-agent: *
Disallow: 

# don't spider the yandex_rss folder
Disallow: /main/rss-yandex-by/

# Add Googlebot-specific syntax extension to exclude forms 
# that are repeated for each piece of content in the site 
# the wildcard is only supported by Googlebot
# http://www.google.com/support/webmasters/bin/answer.py?answer=40367&ctx=sibling

User-Agent: Googlebot
Disallow: /*sendto_form$
Disallow: /*folder_factories$

# wageindicator specific: don't spider searchterm requests
Disallow: /*?searchterm=*
Disallow: /search_rss
Disallow: /search
Disallow: /search_form
Disallow: /*switch_skin=*
Disallow: /*/resolveuid/*


Disallow: /root_images
Disallow: /BingSiteAuth.xml

# Googlebot allows regex in its syntax
# Block all URLs including query strings (? pattern) - contentish objects expose query string
# only for actions or status reports which might confuse search results.
# This will also block ?set_language
User-Agent: Googlebot
Disallow: /*?*

# end wageindicator specific stuff
