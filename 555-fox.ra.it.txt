# L'unica guida esaustiva al linguaggio di robots.txt: https://audisto.com/insights/guides/4/
# For syntax checking, see: http://tool.motoricerca.info/robots-checker.phtml or
# Google's robots.txt analysis tool http://www.google.com/support/webmasters/bin/answer.py?answer=35237

# 08/03/2016
User-agent: Baiduspider
Disallow: /

# https://en.wikipedia.org/wiki/DotBot
User-agent: dotbot
Disallow: /

# Non rispetta il parametro Crawl-delay ed Ã¨ un bot inutile http://domainreanimator.com
User-agent: Domain Re-Animator Bot
Disallow: /

# Succhia banda. spbot/4.4.2; +http://OpenLinkProfiler.org/bot
User-agent: spbot
Disallow: /

# AhrefsBot/5.0; +http://ahrefs.com/robot/
User-agent: AhrefsBot
Disallow: /

User-agent: *
Disallow: /administrator/
Disallow: /cache/
Disallow: /cli/
Disallow: /components/
#Disallow: /images/
Disallow: /includes/
Disallow: /installation/
Disallow: /language/
Disallow: /libraries/
Disallow: /logs/
Disallow: /media/
Disallow: /modules/
Disallow: /plugins/
#Disallow: /templates/
Disallow: /tmp/
# https://en.wikipedia.org/wiki/Robots_exclusion_standard#Crawl-delay_directive
Crawl-delay: 20
