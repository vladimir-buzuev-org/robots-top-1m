# A robots.txt file can be used to prevent access to certain areas by
# Webcrawlers
# 
# Uncomment the example below to prevent one's server being crawled
#
# User-agent: *
# Disallow: /
