# Begin robots.txt file
#/-----------------------------------------------\
#| In single portal/domain situations, uncomment the sitmap line and enter domain name
#\-----------------------------------------------/
#Sitemap: http://dev.ricelake.com/sitemap.aspx


User-agent: *
Disallow: /admin/
Disallow: /App_Browsers/
Disallow: /App_Code/
Disallow: /App_Data/
Disallow: /App_GlobalResources/
Disallow: /bin/
Disallow: /Components/
Disallow: /Config/
Disallow: /contest/
Disallow: /controls/
Disallow: /DesktopModules/
Disallow: /Documentation/
Disallow: /HttpModules/
Disallow: /images/
Disallow: /Install/
Disallow: /js/
Disallow: /Portals/
Disallow: /Providers/
Disallow: /Resources/ContentRotator/
Disallow: /Resources/ControlPanel/
Disallow: /Resources/Dashboard/
Disallow: /Resources/FeedBrowser/
Disallow: /Resources/OpenForceAd/
Disallow: /Resources/Search/
Disallow: /Resources/Shared/
Disallow: /Resources/SkinWidgets/
Disallow: /Resources/TabStrip/
Disallow: /Resources/Widgets/
Disallow: /Activity-Feed/userId/	# Do not index user profiles
Allow: /DesktopModules/rl*/
Allow: /DesktopModules/ToSI*/
Allow: /Portals/0/App/
Allow: /Portals/0/Lib/
Allow: /Portals/0/Skins/
Allow: /Portals/_default/Skins/

User-agent: msnbot
Crawl-delay: 5

User-agent: Slurp
Disallow: /*/ctl/		# Slurp permits *
Crawl-delay: 5

User-agent: Googlebot
Disallow: /*/ctl/		# Googlebot permits *
Allow: .js
Allow: .css

# End of robots.txt file
