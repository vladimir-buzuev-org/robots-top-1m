# robots.txt for http://www.example.com/

User-agent: *
Disallow: /

User-Agent: Googlebot
Allow: /cms/company/

User-Agent: Naverbot
Allow: /cms/company/

User-Agent: Yeti
Allow: /cms/company/

User-Agent: Bingbot
Allow: /cms/company/

User-Agent: Daumoa
Allow: /cms/company/

User-Agent: Msnbot
Allow: /cms/company/

User-Agent: Yahoo! Slurp
Allow: /cms/company/

User-Agent: gomezagent 
Disallow: / 

User-Agent: GomezAgent 
Disallow: / 

User-Agent: gomezagent+1.0 
Disallow: / 

User-Agent: GomezAgent+1.0 
Disallow: / 

User-Agent: gomezagent+2.0 
Disallow: / 

User-Agent: GomezAgent+2.0 
Disallow: / 

User-Agent: gomezagent+3.0 
Disallow: / 

User-Agent: GomezAgent+3.0 
Disallow: / 

User-Agent: *
Disallow: /Static/SessionTimeOut
Disallow: /Static/InvalidLoginToken
Disallow: /Static/FileNotFound
Disallow: /Static/Access
Disallow: /
