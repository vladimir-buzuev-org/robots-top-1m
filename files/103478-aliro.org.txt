# robots.txt file
User-agent: Googlebot
User-agent: Google
User-agent: Bingbot
User-agent: Bing
User-agent: Baiduspider
Crawl-delay: 2
Disallow: /administrator/
Disallow: /bin/
Disallow: /cache/
Disallow: /cli/
Disallow: /components/
Disallow: /includes/
Disallow: /installation/
Disallow: /language/
Disallow: /layouts/
Disallow: /libraries/
Disallow: /logs/
Disallow: /modules/
Disallow: /plugins/
Disallow: /tmp/

User-agent: *
Allow:
