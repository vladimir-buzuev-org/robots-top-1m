# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file

# Disallow
User-Agent: *
Disallow: /temporary/*
Disallow: /search/select_cities?method=GET&amp;url=%2Fsearch
Disallow: /search/select_stations?method=GET&amp;url=%2Fsearch
Disallow: /search/select_occupations?method=GET&amp;url=%2Fsearch
Disallow: /search?keywords=*
Disallow: /search?city_code=*
Disallow: /search?city_codes[]=*
Disallow: /entries/new?job_ids[]=*
Disallow: /newsletters/new?action=*
Disallow: /*form=1*

# Sitemap files
User-Agent: *
Sitemap: https://arubaito-ex.jp/sitemap_keywords.xml.gz
Sitemap: https://arubaito-ex.jp/sitemap_jobs.xml.gz
Sitemap: https://arubaito-ex.jp/keywordpage1.xml
Sitemap: https://arubaito-ex.jp/keywordpage2.xml
Sitemap: https://arubaito-ex.jp/popularsitemap.xml
Sitemap: https://arubaito-ex.jp/popularsitemap1.xml
Sitemap: https://arubaito-ex.jp/popularsitemap2.xml

# Crawl-delay
User-agent: bingbot
Crawl-delay: 5
