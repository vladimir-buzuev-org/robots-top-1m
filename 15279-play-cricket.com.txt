# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:

User-agent: *
Disallow: /website\/player_stats_widget\/batting_stats\/*/
Disallow: /website\/player_stats_widget\/bowling_stats\/*/
Disallow: /website\/player_stats_widget\/batting_stats\/*/
Disallow: /website\/batting_stats_widget\/render_html/
Disallow: /website\/bowling_stats_widget\/render_html/
Disallow: /website\/widgets\/*/
Disallow: /website/web_pages/164721
Disallow: /website/web_pages/164722
Disallow: /website/web_pages/164723
Disallow: /website/web_pages/164724

# Allow only major search spiders    
User-agent: Mediapartners-Google
Disallow:
Crawl-delay: 11

User-agent: Googlebot
Disallow:
Crawl-delay: 12

User-agent: Adsbot-Google
Disallow:
Crawl-delay: 13

User-agent: Googlebot-Image
Disallow:
Crawl-delay: 14

User-agent: Googlebot-Mobile
Disallow:
Crawl-delay: 15

User-agent: MSNBot
Disallow:
Crawl-delay: 16

User-agent: bingbot
Disallow:
Crawl-delay: 17

User-agent: Slurp
Disallow:
Crawl-delay: 18

User-agent: Yahoo! Slurp
Disallow:
Crawl-delay: 19

# Block all other spiders
User-agent: *
Disallow: /






